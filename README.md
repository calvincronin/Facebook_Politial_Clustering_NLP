The Cambridge Analytica scandal of the 2010’s remains one of the more infamous instances of large scale corporate data abuse. The profiles of tens of millions of Facebook users were harvested without their consent and used to build classification models for microtargeting. The purpose of these models was to more accurately target susceptible users with political advertisements, most notably for the 2016 presidential campaigns of Ted Cruz and Donald Trump.
In the aftermath, Facebook deployed measures for regaining collective user and consumer trust. In an effort to prevent a similar situation and demonstrate transparency, they published their Ad Library. This library makes all current and prior advertisements on Meta owned platforms (Facebook, Instagram, WhatsApp) accessible to the public. Queries return not just the contents of the ad, but the advertising parameters as well. Dates of ad runtime, spending, geographic/demographic targeting, and estimated views are a few examples of fields that could give meaningful insights at the aggregate level.
All that remains is an algorithmic approach to grouping these advertisements into political party affiliations. In this case, the Democrat and Republican parties that comprise the U.S. two-party system. Research in this space is fairly sparse at the moment, and there are no labeled datasets currently available. So the scope of this paper excludes classification models or analyzing advertisements post-grouping. The contribution is instead optimizing combinations of word vectorization and unsupervised learning techniques for the purpose of grouping into expected political identities.

Section 2 delves into the collection of related works. Section 3 examines the challenges and measures of data processing. Text vectorization is not included here, but instead found in Section 4 along with unsupervised learning efforts.
2 Literature Review
To contextualize this paper amongst related works, the unique challenges of the task at hand must first be addressed to some extent. The goal of mapping corpus documents to a political party does not fit squarely under any of the standard NLP approaches. Ultimately similarly focused techniques, or components of them, will form the collection of tools used to pursue this goal.
The challenge with political advertising data is that its directionality and focus varies. Conservative ads may be pro-conservative or anti-liberal, and vice versa. Or either may focus on a specific external topic. So if Bag-of-Words (BoW) or TF-IDF are used for feature generation, it may not fare well using orderless term frequency. Therefore, some approaches will inevitably incorporate semantic preserving algorithms like word2vec (or its generalizations like doc2vec) as originally presented by (Mikolov et al. 2013). And contemporary transformer-based models like Sentence-BERT (Reimers, and Gurevych 2019) could further improve embedding models for the overall comparison.
Using stock LDA for topic modeling would be subject to similar pitfalls as BoW and TF-IDF. So further utilizing word2vec generalizations, making use of embedding focused and semantically aware algorithms like those found in (Angelov 2020, 1-25) ) are essential for successful topic modeling here.
There are also entirely different unsupervised learning approaches that may yield meaningful results. In an up to date and comprehensive look at natural language models, (Eisenstein 2019, 96-122) demonstrates stance classification, an unsupervised learning technique closer to sentiment analysis in nature, but worth assessing in the scope of political affiliation.
The most directly related works in terms of application are that of (Pierri 2022, 1-10) and (Vrancken 2022, 1-16). They both make use of Meta’s ad library with the goal of grouping by some political outlook. The former uses a mix of querying partisan candidate names and manual labeling. The latter uses partial NLP preprocessing with ad contents. For grouping it uses a custom word frequency algorithm to classify records into themes, according to that theme’s predefined collection of words.

3 Data Processing
The data is fairly accessible and allows for query filters to return a specific collection of advertisements. Section 3.1 elaborates on this selection process. While the data is accessible, its contents are unruly. Meta allows for fairly robust customization of its advertisements, so each is a varied mixture of text, images, videos, hyperlinks, etc. Section 3.2 details the processing that is necessary prior to vectorization.
3.1 Data Sourcing
In (Vrancken 2022, 2-3) the structure of the Ad Library and its data are laid out in great detail. There are two primary means of data retrieval. An API and a search bar tool with filtering and sorting options. The objective is to compare methods, not to create a production level tool.Sso the manual search is sufficient here.
3.1.1 Filters used on search bar queries:
● Categorized as “Issues, Elections, or Politics”.
● United States based.
● Text in English.
● Active between 3/1/23 and 4/30/22.
These filters were used to get a small but recent sample of United States political advertising. The “Issues, Elections, or Politics” category returns a number of ads unrelated to the two-party system. So the corpus was eventually composed of separate searches for “Republican” and “Democrat”, both issued with the filters in 3.1.1.
3.2 Data Preparation
Data from the two searches was combined into a single file. At this point, each record in the dataset represents a unique advertisement instance, which does not imply unique content. Many platform users ran the same ad for multiple separate time periods, resulting in separate data points with identical content. Similarly, many ads did not have entries in the main text section of the ad, instead electing for a short tagline and accompanying link or embedded picture. So entries with duplicate or missing values in the “ad_creative_bodies” field were removed from the dataset.
The ads also varied significantly in terms of word length, and skewed towards shorter text bodies. An ideal corpus would have a reasonable number of documents, and the documents 4
would have word counts of substantial, yet comparable, sizes. Empirically, a corpus composed only of documents with 200-400 words best fit these conditions, so all other documents were removed.
The final corpus has 89 documents. 64 from the “Republican” query, and 25 from the “Democrat” query. But because of the challenges with narrative direction mentioned in Section 2, this breakdown by searchword does not necessarily imply their political affiliation. In order to gauge the efficacy of the different clustering or topic modeling methods, each of the 89 documents were manually labeled with the appropriate political affiliation. The documents of this corpus were tokenized, had punctuation and stopwords removed, lemmatized and stemmed using the regex and nltk python libraries.
4 Methods
The general procedure followed a comprehensive and structured path of comparison. This featured one primary comparison workflow, and two auxiliary efforts. In the primary comparison, the corpus was vectorized with several different methods, each set of vectors underwent dimensionality reduction, and finally each vector was fit to a handful of clustering algorithms. The two auxiliary workflows were Topic Modeling and Hierarchical Clustering, respectively. These were treated as separate workflows because getting comparable results for these requires different processes.
4.1 Primary Comparison Procedures
During this stage, there were four text vectorization methods implemented and the output of each was subjected to two different clustering algorithms for a total of eight sets of results. In between the vectorization and clustering steps, Principal Component Analysis (PCA) was performed on each of the four sets of vectorized text and plotted with data points corresponding to their known political labeling. The plots provide a visual measure of the degree to which the data can be reasonably clustered into expected groups. So the plots aided in tuning vectorization function parameters, as well as contextualizing final results.
4.1.1 Vectorization Methods
● TFIDF
● Word2vec
● Doc2vec
● BERT 5
For the implementation of Word2Vec, a custom function was used to generate vectors for each document using a word embedding. For the BERT-based method, a pre-trained sentence transformer model was used.
4.1.2 Primary Clustering Methods
● K-Means
● DBSCAN
Generally DBSCAN is a more sensitive method. There is a process to derive its ideal parameters, of which small deviations from can result in the model failing to create clusters. It can also be uprooted by input data with a large feature count. So to get the model to work consistently, the principal component vectors were input instead of the actual vectorized text.
For both the text vectorization and clustering methods, there was significant parameter tuning in an effort to maximize clustering of documents according to expected labeling. Each final method was tested with a number of random seeds to ensure consistency in the results.
4.2 Topic Modeling
We implemented two topic modeling algorithms, LDA and Top2vec. For LDA, the model was fed the corpus as a BoW. For Top2vec, the topics were generated with a pre-trained transformer word embedding model. In both cases, after the topics were derived, each document was labeled with the topic that it had the highest propensity towards. Then using the proportions of political identity for documents highly related to a given topic, all highly related documents for that topic would be viewed as “Democrat” or “Republican” according to the model.
4.3 Hierarchical Clustering
Hierarchical Clustering was also implemented for all four sets of vectorized text, but without any sort of dimensionality reduction to guide. A cosine similarity was computed for each set of vectors, which was used to define a linkage matrix with ward agglomerative clustering. This matrix was used to create a dendrogram, where documents under a handful of high level hierarchical groupings would be counted as “Democrat” or “Republican” depending on the proportion of actual political identities in that group.
6
5 Results
The objective is to produce an accurate and repeatable method of segmenting documents by political affiliation, without having to train a classification method. So for the different methods, as long as some logic could be imparted on their output to strain out liberal and conservative documents, and that logic-output relationship would generalize well, then that method was evaluated accordingly.
The general idea behind evaluation was to have a given model infer political identity labels for documents that are grouped together. If there was an obvious majority of a grouping’s actual political identities, the majority identity was assumed for the entire grouping. Evaluation metrics were derived from the total number or correctly inferred document political identities. For example, if a cluster had 12 documents with actual labels of Democrat and 2 documents with actual labels of Republican, the cluster would be assumed to be a democratic one, with 12 correct out of the 14 documents in that cluster. This would be totaled for all groups in a given model’s output, and an overall percent of correctly attributed documents would be calculated. This evaluation metric was calculated regardless of a model's output structure. For example a single model could produce multiple topics or clusters deemed “Republican”. Section 6 goes into more depth on the results shown in this section.
5.1 Text Vectorization and Clustering
Fig 5.1.1 shows the results for the 8 models resulting from combinations of 4 text vectorization approaches with 2 two clustering algorithms.

![image](https://github.com/user-attachments/assets/e5091b36-0dc6-4b8d-8a7a-5f4bd9eff3c7)

In terms of text vectorization, TFIDF produced the best results, followed by BERT. Word2vec and Doc2vec did not exhibit a significantly better ability to segment by political identity than if political identities were guessed at random. K-means seems to generally perform better than DBSCAN. Overall the best performing model was TFIDF with K-means, demonstrating the ability to correctly group 74% of a corpus by political identity.
5.2 Topic Modeling
LDA with BoW failed to generate sufficient topics. Regardless of the number of output topics generated, they were always functionally indistinguishable from each other. The majority of words in one topic were usually present in other topics, and with very similar coefficients. See Appendix Figure 1. As unique topics were never generated, political identities of documents were not inferred. Top2vec with sentence embeddings exhibited an almost identical inability to create distinguishable topics, and groupings were not generated for evaluation.
5.3 Hierarchical Clustering
The hierarchical clustering models produced output structurally different from clustering in section 5.1. Similar to that section, word2vec and doc2vec dendrograms did not successfully group documents with similar political affiliation. But TFIDF and BERT produced dendrograms where some high level sub-hierarchies grouped similarly affiliated documents very well, and other sub-hierarchies did not at all. So the evaluation of these will be slightly different than in 5.1. It is based on an interpretation of the output where hierarchies of ambiguous political identity are removed and the remaining hierarchies are evaluated as in 5.1. For TFIDF and BERT, Figure 5.3.1 shows how much of the output was usable and how well that remaining output grouped documents as expected.

![image](https://github.com/user-attachments/assets/b41d04fe-6af5-4407-a1a5-46954cf144bc)

6 Analysis and Interpretation
The results of the overall comparison seemed somewhat unexpected initially, but looking at them retrospectively and in context can help to reconcile these observations. The driving forces behind what worked and what didn’t work form valuable lessons for this sort of endeavor.
Looking first at what didn’t work, all Topic Mapping exercises unmistakably failed. Regardless of text vectorization, transformers, or contemporary methods, all efforts failed to create reasonable topics, let alone group documents well. There are a handful of concepts that could tie to these failures. Topic Mapping is fundamentally different from clustering because the topic - document relationship is not as rigid. Each document can be associated (to varying degrees) with multiple topics. So in retrospect, it was a fairly roundabout and indirect way to go about inferring binary political identities to documents. So it came to be clear that it was ill-fitted to the task at hand. Additionally the models were more restrictive in what they can accept for text vectorization. With the Gensim python library, LDA could only be generated from BoW, and the Top2Vec library only allows for pre-trained word embeddings, so this proved restrictive. Lastly, the dataset was challenging to begin with. Many of the data points were extremely similarly worded, like candidacy announcements. And the dataset was already fairly focused (US Politics, Democrat and Republican) so this could have left little room for sub topics given the relatively small size of the data. It's reasonable given the challenges of working with real world data.
One of the more unexpected failures was the embedding model approach taken with word2vec and doc2vec. For all unsupervised methods tested, they seemed to be just about marginally better than making inferences at random. This was surprising considering the initial expectation that semantically aware embedding models would fare better in dealing with the bidirectionality of different political narratives referencing both themselves and the opposite party. But the model taking into account semantics may not have been ideal in this case.
Looking at the data, ads from republican and democratic sources are actually much more semantically similar than they are different. The majority of the ads were spreading awareness about a given candidate, which were very similar word frequency and semantics wise, regardless of that candidate’s political party. Many never mention the candidate's political party. There were also instances where the ad was politically charged, but the stance was unclear. For example, if the subject was a piece of conservative legislation passing, was the ad celebrating it as a republican or condemning it as a democrat? See Appendix 2 for an example. For these reasons, the data was actually difficult to even manually label, let alone tune an algorithm to do so. Overall it seems like a word embedding approach assimilated the data somewhat and ultimately made it impossible to form cleanly grouped clusters at all.
9
When you look at the PCA graphs below for TFIDF vs doc2vec, colored by actual political party, you can visually see that one is much easier to cluster by political party than the other.
6.1
![image](https://github.com/user-attachments/assets/0c319cbe-fac0-4afb-a00b-19fe3e119feb)
![image](https://github.com/user-attachments/assets/1733d1a2-3b74-4e05-b2f1-fdaa292e7bcb)
7. Conclusion
Ultimately K-means with TFIDF resulted in the best unsupervised model to group political advertisement documents by political party. Based on the results, if one were to use this model with k =2, they could expect to group documents with about 74% accuracy. This is a promising result, but not sufficient for the purpose of using clustering to generate a dataset for classification, nor to report metrics on.
References
Angelov, Dimo. "Top2vec: Distributed representations of topics." arXiv:2008.09470 [cs.CL] (Aug. 19, 2020), https://arxiv.org/pdf/2008.09470.pdf.
Bojanowski, Piotr, Edouard Grave, Armand Joulio, and Tomas Mikolov. “Enriching Word ... Vectors with Subword Information.” Transactions of the Association for Computational x.xLinguistics 5, no. 1 (July 2016): 135-146. doi:10.1162/tacl_a_0051.
Eisenstein, Jacob. 2019. Introduction to Natural Language Processing. United Kingdom: MIT Press.
Reimers, Nils, and Iryna Gurevych. "Sentence-bert: Sentence Embeddings using Siamese BERT-Networks." arXiv:1908.10084 [cs.CL] (Aug. 27, 2019), https://arxiv.org/pdf/1908.10084.pdf.
Pierri, Francesco. "Political advertisement on Facebook and Instagram in the run-up to 2022 Italian general election." arXiv:2212.08021v2 [cs.CY] (Feb. 8, 2023), https://arxiv.org/pdf/2212.08021.pdf.
Vrancken, Joren. "Theme Analysis of Political Facebook Ads in the 2021 Dutch General Election." arXiv:2201.04533 [cs.SI] (Jan 12, 2022), https://arxiv.org/pdf/2201.04533.pdf.
